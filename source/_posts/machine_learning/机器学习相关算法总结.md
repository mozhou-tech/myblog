title: 机器学习相关算法总结
date: 2016-05-03 21:55:26
tags:
- 机器学习
- 数据挖掘
- 金融
- 金融预测
- 算法
categories:
- IT技术
- 机器学习
---
从Quantitative Modeling的角度来说，有两大主流的方向：Stochastic Calculus（随机微积分）和Statistical Learning（统计学习）。

机器学习的常用方法，主要分为有监督学习(supervised learning)和无监督学习(unsupervised learning)。监督学习，就是人们常说的分类，通过已有的训练样本（即已知数据以及其对应的输出）去训练得到一个最优模型（这个模型属于某个函数的集合，最优则表示在某个评价准则下是最佳的），再利用这个模型将所有的输入映射为相应的输出，对输出进行简单的判断从而实现分类的目的，也就具有了对未知数据进行分类的能力。
![](/images/2016/machine_learning_algorithms.png)

### [决策树 (Decision tree)](https://zh.wikipedia.org/wiki/%E5%86%B3%E7%AD%96%E6%A0%91)
机器学习中，决策树是一个预测模型；他代表的是对象属性与对象值之间的一种映射关系。树中每个节点表示某个对象，而每个分叉路径则代表的某个可能的属性值，而每个叶结点则对应从根节点到该叶节点所经历的路径所表示的对象的值。决策树仅有单一输出，若欲有复数输出，可以建立独立的决策树以处理不同输出。
![](/images/2016/decision_tree.png)

### [K-近邻算法 (K-nearest neighbors, KNN)](https://zh.wikipedia.org/wiki/%E6%9C%80%E8%BF%91%E9%84%B0%E5%B1%85%E6%B3%95)
在模式识别领域中，最近邻居法（KNN算法，又译K-近邻算法）是一种用于分类和回归的非参数统计方法。在这两种情况下，输入包含特征空间中的k个最接近的训练样本。
![](/images/2016/knn_algorithm.png)

### [朴素贝叶斯分类器（Naive Bayes classifier）](https://zh.wikipedia.org/wiki/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%88%86%E7%B1%BB%E5%99%A8)
在机器学习中，朴素贝叶斯分类器是一系列以假设特征之间强（朴素）独立下运用贝叶斯定理为基础的简单概率分类器。
![](/images/2016/nlp-naive-bayes.jpg)

### [逻辑回归 (Logistic regression)](https://zh.wikipedia.org/wiki/%E9%82%8F%E8%BC%AF%E8%BF%B4%E6%AD%B8)
logistic回归又称logistic回归分析，是一种广义的线性回归分析模型，常用于数据挖掘，疾病自动诊断，经济预测等领域。例如，探讨引发疾病的危险因素，并根据危险因素预测疾病发生的概率等。
![](/images/2016/logistic_linear_regression_compare.png)
![](/images/2016/logistic_sigmoid_function.png)

### [支持向量机(SVM)](https://zh.wikipedia.org/wiki/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA)
支持向量机属于一般化线性分类器，也可以被认为是提克洛夫规范化（Tikhonov Regularization）方法的一个特例。这族分类器的特点是他们能够同时最小化经验误差与最大化几何边缘区，因此支持向量机也被称为最大边缘区分类器。
![](/images/2016/svm_classifier.png)

### [随机森林 (Random Forest)](https://zh.wikipedia.org/wiki/%E9%9A%8F%E6%9C%BA%E6%A3%AE%E6%9E%97)
在机器学习中，随机森林是一个包含多个决策树的分类器，并且其输出的类别是由个别树输出的类别的众数而定。Leo Breiman和Adele Cutler发展出推论出随机森林的算法。
![](/images/2016/random_forest.gif)
[1] [random forest interpretation with scikit-learn](http://blog.datadive.net/random-forest-interpretation-with-scikit-learn/) [[译文]](http://www.csdn.net/article/2015-10-08/2825851)
[2] [随机森林入门攻略](http://datartisan.com/article/detail/42.html)
[3] [示例解析：sklearn中的随机森林算法RandomForestClassifier](http://blog.itpub.net/12199764/viewspace-1572056/)

### [感知器 (Perceptron)](https://zh.wikipedia.org/wiki/%E6%84%9F%E7%9F%A5%E5%99%A8)
Frank Rosenblatt在1957年就职于Cornell航空实验室（Cornell Aeronautical Laboratory）时所发明的一种人工神经网络。它可以被视为一种最简单形式的前馈神经网络，是一种二元线性分类器。
![](/images/2016/perceptron_neural_network.png)

### [人工神经网络 (artificial neural network, ANN)](https://zh.wikipedia.org/wiki/%E4%BA%BA%E5%B7%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)
现代神经网络是一种非线性统计性数据建模工具，常用来对输入和输出间复杂的关系进行建模，或用来探索数据的模式。神经网络是一种运算模型，由大量的节点（或称“神经元”，或“单元”）和之间相互联接构成。每个节点代表一种特定的输出函数，称为激励函数（activation function）。
![](/images/2016/neural-network.png)

### [深度神经网络 (deep neuron networks, DNN)](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0)
是一种具备至少一个隐层的神经网络。与浅层神经网络类似，深度神经网络也能够为复杂非线性系统提供建模，但多出的层次为模型提供了更高的抽象层次，因而提高了模型的能力。深度神经网络通常都是前馈神经网络，但也有语言建模等方面的研究将其拓展到递归神经网络。
![Understanding LSTM Networks](/images/deep_neural_network.png)

### [循环神经网络 (Recurrent Neural Networks, RNN)](https://zh.wikipedia.org/wiki/%E9%80%92%E5%BD%92%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)
递归神经网络（RNN）是两种人工神经网络的总称。一种是时间递归神经网络（recurrent neural network），另一种是结构递归神经网络（recursive neural network）。时间递归神经网络的神经元间连接构成有向图，而结构递归神经网络利用相似的神经网络结构递归构造更为复杂的深度网络。RNN一般指代时间递归神经网络。单纯递归神经网络因为无法处理随着递归，权重指数级爆炸或消失的问题（Vanishing gradient problem），难以捕捉长期时间关联；而结合不同的LSTM可以很好解决这个问题。
![](/images/2016/sample_of_rnn_network.png)
[1][Understanding LSTMs](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
[2][长短记忆人工神经网络(LSTM)](https://zh.wikipedia.org/wiki/LSTM)

### [卷积神经网络 (convolutional neuron networks，CNN)](https://zh.wikipedia.org/wiki/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C)
由一个或多个卷积层和顶端的全连通层（对应经典的神经网络）组成，同时也包括关联权重和池化层（pooling layer）。这一结构使得卷积神经网络能够利用输入数据的二维结构。与其他深度学习结构相比，卷积神经网络在图像和语音识别方面能够给出更优的结果。
![](/images/2016/cnn_architecture.jpg)

### [梯度下降法 (Gradient descent)](https://zh.wikipedia.org/wiki/%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E6%B3%95)
是一个最优化算法，通常也称为最速下降法，常用于机器学习和人工智能当中用来递归性地逼近最小偏差模型。
![](/images/2016/gradient_descent.png)

[1] [Get off the deep learning bandwagon and get some perspective](http://www.pyimagesearch.com/2014/06/09/get-deep-learning-bandwagon-get-perspective/)
[2] [How to choose algorithms for Microsoft Azure Machine Learning](https://azure.microsoft.com/en-us/documentation/articles/machine-learning-algorithm-choice/)
[3] [斯坦福大学机器学习公开课](http://pan.baidu.com/s/1o8ktHn8) 密码: a95n
[4] [List of machine learning concepts](https://en.wikipedia.org/wiki/List_of_machine_learning_concepts)
[5] [Machine Learning GUI Software Weka](http://www.cs.waikato.ac.nz/ml/index.html)
[6] [CSDN xbinworld研究机器学习算法的博文](http://blog.csdn.net/xbinworld/article/details/44464663)




